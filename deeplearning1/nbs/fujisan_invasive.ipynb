{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2282e0e6-bed3-4375-5b9b-05c80fe29f27"
   },
   "source": [
    "use Keras pre-trained VGG16\n",
    "---------------------------\n",
    "this is my first notebook. \n",
    "\n",
    "pre-trained VGG16 is quickly and good performance.\n",
    "\n",
    "I learned from official Keras blog tutorial \n",
    "[Building powerful image classification models using very little data][1]\n",
    "\n",
    "\n",
    "  [1]: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fdca4192-cf9d-1f5f-7e8f-30ae5e468db4"
   },
   "source": [
    "## resize train data and test data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "aab06a15-51b8-13e2-172a-b3e62aa3738a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  invasive\n",
       "0     1         0\n",
       "1     2         0\n",
       "2     3         1\n",
       "3     4         0\n",
       "4     5         1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "master = pd.read_csv(\"../input/train_labels.csv\")\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e68a78fc-8470-e081-27ad-eca99e6fdd1f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = \"../input/train/\"\n",
    "\n",
    "y = []\n",
    "file_paths = []\n",
    "for i in range(len(master)):\n",
    "    file_paths.append( img_path + str(master.ix[i][0]) +'.jpg' )\n",
    "    y.append(master.ix[i][1])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "34636940-b7b8-64f6-6ca7-1ad97081ea7b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#image reseize & centering & crop \n",
    "\n",
    "def centering_image(img):\n",
    "    size = [256,256]\n",
    "    \n",
    "    img_size = img.shape[:2]\n",
    "    \n",
    "    # centering\n",
    "    row = (size[1] - img_size[0]) // 2\n",
    "    col = (size[0] - img_size[1]) // 2\n",
    "    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n",
    "    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n",
    "\n",
    "    return resized\n",
    "\n",
    "\n",
    "x = []\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #resize\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "    #centering\n",
    "    img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "    \n",
    "    #out put 224*224px \n",
    "    img = img[16:240, 16:240]\n",
    "    x.append(img)\n",
    "\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1f371b5e-579e-cd78-51f3-bad30c864a85",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "img_path = \"../input/test/\"\n",
    "\n",
    "test_names = []\n",
    "file_paths = []\n",
    "\n",
    "for i in range(len(sample_submission)):\n",
    "    test_names.append(sample_submission.ix[i][0])\n",
    "    file_paths.append( img_path + str(int(sample_submission.ix[i][0])) +'.jpg' )\n",
    "    \n",
    "test_names = np.array(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "8f849642-855e-63b0-26e8-107724628353",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for file_path in file_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #resize\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "    #centering\n",
    "    img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "    \n",
    "    #out put 224*224px \n",
    "    img = img[16:240, 16:240]\n",
    "    test_images.append(img)\n",
    "    \n",
    "    path, ext = os.path.splitext( os.path.basename(file_paths[0]) )\n",
    "\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d5db4fe-b1ca-80d9-eb5a-decb9e71fa8b"
   },
   "source": [
    "save numpy array.\n",
    "\n",
    "Usually I separate code, data format and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "54ee247b-1228-bfb2-46c0-0b08e3455375",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savez('224.npz', x=x, y=y, test_images=test_images, test_names=test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2880329f-76a5-b385-a3ba-609820535f34"
   },
   "source": [
    "## split train data and validation data  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "aea9535d-9baa-214c-afd1-1595ae44cb0f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_num = len(y)\n",
    "random_index = np.random.permutation(data_num)\n",
    "\n",
    "x_shuffle = []\n",
    "y_shuffle = []\n",
    "for i in range(data_num):\n",
    "    x_shuffle.append(x[random_index[i]])\n",
    "    y_shuffle.append(y[random_index[i]])\n",
    "    \n",
    "x = np.array(x_shuffle) \n",
    "y = np.array(y_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "3aa4f607-c45c-c738-3b99-ced4f3fa5a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (1836, 224, 224, 3)\n",
      "y_train (1836,)\n",
      "x_test (459, 224, 224, 3)\n",
      "y_test (459,)\n"
     ]
    }
   ],
   "source": [
    "val_split_num = int(round(0.2*len(y)))\n",
    "x_train = x[val_split_num:]\n",
    "y_train = y[val_split_num:]\n",
    "x_test = x[:val_split_num]\n",
    "y_test = y[:val_split_num]\n",
    "\n",
    "print('x_train', x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('x_test', x_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "8b6caf1c-bc20-63cb-52a3-33dc71c5529d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9fa975c5-3996-8f40-65c0-a49c09ec26ae"
   },
   "source": [
    "use Keras pre-trained VGG16\n",
    "---------------------------\n",
    "\n",
    "but kaggle karnel is not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "18861ee9-b81b-27ef-3846-0d04aafd3560"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; got `input_shape=(224, 224, 3)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0287e0db5c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, classes)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                       \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dim_ordering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                       include_top=include_top)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, dim_ordering, include_top)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n\u001b[0;32m--> 117\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    118\u001b[0m                 if ((input_shape[1] is not None and input_shape[1] < min_size) or\n\u001b[1;32m    119\u001b[0m                    (input_shape[2] is not None and input_shape[2] < min_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; got `input_shape=(224, 224, 3)`"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "a7b158cf-ed3e-6ebc-868f-acddcce92344"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c359507f3282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0madd_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0madd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0madd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, output=add_model(base_model.output))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "ecf8491d-cbba-505d-e5d8-fecaae32e35e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2e0a31593721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e0e5efc6-cf1a-32fb-5b2e-d1ea2b244a5d"
   },
   "source": [
    "## predict test data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "8c3ac15d-fb29-2531-cbe5-f763c35623a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_images.astype('float32')\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "7740ecc9-98c6-c62b-f71e-69d8c34ed451"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4f3b02264dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "a90d25c4-6587-a574-27db-5af5e9ff17d3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8d1f4d5c4cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'invasive'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "\n",
    "for i, name in enumerate(test_names):\n",
    "    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = predictions[i]\n",
    "\n",
    "sample_submission.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d36278d-01ef-c87b-3710-bf3820562913"
   },
   "source": [
    "What to do next?\n",
    "----------------\n",
    "\n",
    "I will try pre-trained ResNet, fine tune ResNet.\n",
    "\n",
    "This idea seems to be helpful.\n",
    "\n",
    "[Dogs vs. Cats Redux Playground Competition, 3rd Place Interview][1]\n",
    "\n",
    "\n",
    "  [1]: http://blog.kaggle.com/2017/04/20/dogs-vs-cats-redux-playground-competition-3rd-place-interview-marco-lugo/"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 5,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
